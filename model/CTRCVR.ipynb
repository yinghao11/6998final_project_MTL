{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"CTRCVR.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/10tVYQyAJZH_ZK3mC-0X_fViLOdxG8Hl9\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import optimizers\n",
    "import time\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "tf.config.set_soft_device_placement(False)\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n",
    "\n",
    "\n",
    "class CTCVRNet:\n",
    "    def __init__(self):\n",
    "        self.user_feature_num = 0\n",
    "        self.item_feature_num = 0\n",
    "\n",
    "    def build_ctr_model(self, ctr_user_numerical_input, ctr_user_cate_input, ctr_item_numerical_input,\n",
    "                        ctr_item_cate_input):\n",
    "\n",
    "        user_feature = layers.Dropout(0.5)(ctr_user_numerical_input)\n",
    "        user_feature = layers.BatchNormalization()(user_feature)\n",
    "        user_feature = layers.Dense(128, activation='relu')(user_feature)\n",
    "        user_feature = layers.Dense(64, activation='relu')(user_feature)\n",
    "\n",
    "        item_feature = layers.Dropout(0.5)(ctr_item_numerical_input)\n",
    "        item_feature = layers.BatchNormalization()(item_feature)\n",
    "        item_feature = layers.Dense(128, activation='relu')(item_feature)\n",
    "        item_feature = layers.Dense(64, activation='relu')(item_feature)\n",
    "\n",
    "        dense_feature = layers.concatenate(\n",
    "            [user_feature, item_feature], axis=-1)\n",
    "        dense_feature = layers.Dropout(0.5)(dense_feature)\n",
    "        dense_feature = layers.BatchNormalization()(dense_feature)\n",
    "        dense_feature = layers.Dense(64, activation='relu')(dense_feature)\n",
    "        pred = layers.Dense(1, activation='sigmoid',\n",
    "                            name='ctr_output')(dense_feature)\n",
    "        return pred\n",
    "\n",
    "    def build_cvr_model(self, cvr_user_numerical_input, cvr_user_cate_input, cvr_item_numerical_input,\n",
    "                        cvr_item_cate_input):\n",
    "\n",
    "        user_feature = layers.Dropout(0.5)(cvr_user_numerical_input)\n",
    "        user_feature = layers.BatchNormalization()(user_feature)\n",
    "        user_feature = layers.Dense(128, activation='relu')(user_feature)\n",
    "        user_feature = layers.Dense(64, activation='relu')(user_feature)\n",
    "\n",
    "        item_feature = layers.Dropout(0.5)(cvr_item_numerical_input)\n",
    "        item_feature = layers.BatchNormalization()(item_feature)\n",
    "        item_feature = layers.Dense(128, activation='relu')(item_feature)\n",
    "        item_feature = layers.Dense(64, activation='relu')(item_feature)\n",
    "\n",
    "        dense_feature = layers.concatenate(\n",
    "            [user_feature, item_feature], axis=-1)\n",
    "        dense_feature = layers.Dropout(0.5)(dense_feature)\n",
    "        dense_feature = layers.BatchNormalization()(dense_feature)\n",
    "        dense_feature = layers.Dense(64, activation='relu')(dense_feature)\n",
    "        pred = layers.Dense(1, activation='sigmoid',\n",
    "                            name='cvr_output')(dense_feature)\n",
    "        return pred\n",
    "\n",
    "    def build(self):\n",
    "        # CTR model input\n",
    "        ctr_user_numerical_input = layers.Input(shape=(self.user_feature_num,))\n",
    "        ctr_user_cate_input = layers.Input(shape=(1,))\n",
    "        ctr_item_numerical_input = layers.Input(shape=(self.item_feature_num,))\n",
    "        ctr_item_cate_input = layers.Input(shape=(1,))\n",
    "\n",
    "        # CVR model input\n",
    "        cvr_user_numerical_input = layers.Input(shape=(self.user_feature_num,))\n",
    "        cvr_user_cate_input = layers.Input(shape=(1,))\n",
    "        cvr_item_numerical_input = layers.Input(shape=(self.item_feature_num,))\n",
    "        cvr_item_cate_input = layers.Input(shape=(1,))\n",
    "\n",
    "        ctr_pred = self.build_ctr_model(ctr_user_numerical_input, ctr_user_cate_input, ctr_item_numerical_input,\n",
    "                                        ctr_item_cate_input)\n",
    "        cvr_pred = self.build_cvr_model(cvr_user_numerical_input, cvr_user_cate_input, cvr_item_numerical_input,\n",
    "                                        cvr_item_cate_input)\n",
    "        ctcvr_pred = tf.multiply(ctr_pred, cvr_pred)\n",
    "        model = Model(\n",
    "            inputs=[ctr_user_numerical_input, ctr_user_cate_input, ctr_item_numerical_input, ctr_item_cate_input,\n",
    "                    cvr_user_numerical_input, cvr_user_cate_input, cvr_item_numerical_input, cvr_item_cate_input],\n",
    "            outputs=[ctr_pred, ctcvr_pred])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def preprocess_data(self, data, labels):\n",
    "        _data = data.loc[(data[labels[0]] != -1) & (data[labels[1]] != -1)]\n",
    "        print(data)\n",
    "        if _data.shape[0] <= 10:\n",
    "            data.replace(-1, 0, inplace=True)\n",
    "        else:\n",
    "            data = _data\n",
    "        sample_num = data.shape[0]\n",
    "\n",
    "        if sample_num % 2 == 1:\n",
    "            sample_num -= 1\n",
    "            data = data[1:]\n",
    "\n",
    "        half_data_num = int(sample_num/2)\n",
    "        train_sample_num = int(half_data_num*0.6)\n",
    "        val_sample_num = int(half_data_num*0.2)\n",
    "        test_sample_num = half_data_num - train_sample_num - val_sample_num\n",
    "        feature_num = data.shape[1]-len(labels)\n",
    "\n",
    "        features = list(set(data.columns)-set(labels))\n",
    "        self.user_feature_num = feature_num//2\n",
    "        self.item_feature_num = feature_num-self.user_feature_num\n",
    "\n",
    "        user_features = features[:self.user_feature_num]\n",
    "        item_features = features[self.user_feature_num:]\n",
    "\n",
    "        data0 = data[:half_data_num]\n",
    "        data1 = data[half_data_num:]\n",
    "\n",
    "        X0_data_user = data0[user_features]\n",
    "        X1_data_user = data1[user_features]\n",
    "        X0_data_item = data0[item_features]\n",
    "        X1_data_item = data1[item_features]\n",
    "        Y0_data = data0[labels[0]]\n",
    "        Y1_data = data1[labels[1]]\n",
    "\n",
    "        X0_data_user_test = X0_data_user[train_sample_num+val_sample_num:]\n",
    "        X1_data_user_test = X1_data_user[train_sample_num+val_sample_num:]\n",
    "        X0_data_item_test = X0_data_item[train_sample_num+val_sample_num:]\n",
    "        X1_data_item_test = X1_data_item[train_sample_num+val_sample_num:]\n",
    "        Y0_data_test = Y0_data[train_sample_num+val_sample_num:]\n",
    "        Y1_data_test = Y1_data[train_sample_num+val_sample_num:]\n",
    "\n",
    "        X0_data_user_val = X0_data_user[train_sample_num:train_sample_num+val_sample_num]\n",
    "        X1_data_user_val = X1_data_user[train_sample_num:train_sample_num+val_sample_num]\n",
    "        X0_data_item_val = X0_data_item[train_sample_num:train_sample_num+val_sample_num]\n",
    "        X1_data_item_val = X1_data_item[train_sample_num:train_sample_num+val_sample_num]\n",
    "        Y0_data_val = Y0_data[train_sample_num:train_sample_num+val_sample_num]\n",
    "        Y1_data_val = Y1_data[train_sample_num:train_sample_num+val_sample_num]\n",
    "\n",
    "        X0_data_user = X0_data_user[:train_sample_num]\n",
    "        X1_data_user = X1_data_user[:train_sample_num]\n",
    "        X0_data_item = X0_data_item[:train_sample_num]\n",
    "        X1_data_item = X1_data_item[:train_sample_num]\n",
    "        Y0_data = Y0_data[:train_sample_num]\n",
    "        Y1_data = Y1_data[:train_sample_num]\n",
    "\n",
    "        train_data = [X0_data_user, pd.DataFrame(np.zeros(train_sample_num)), X0_data_item,\n",
    "                      pd.DataFrame(np.zeros(train_sample_num)), X1_data_user, pd.DataFrame(\n",
    "                          np.zeros(train_sample_num)),\n",
    "                      X1_data_item, pd.DataFrame(np.zeros(train_sample_num)), pd.DataFrame(Y0_data), pd.DataFrame(Y1_data)]\n",
    "\n",
    "        val_data = [X0_data_user_val, pd.DataFrame(np.zeros(val_sample_num)), X0_data_item_val,\n",
    "                    pd.DataFrame(np.zeros(val_sample_num)), X1_data_user_val, pd.DataFrame(\n",
    "                        np.zeros(val_sample_num)),\n",
    "                    X1_data_item_val, pd.DataFrame(np.zeros(val_sample_num)), pd.DataFrame(Y0_data_val), pd.DataFrame(Y1_data_val)]\n",
    "\n",
    "        test_data = [X0_data_user_test, pd.DataFrame(np.zeros(test_sample_num)), X0_data_item_test,\n",
    "                     pd.DataFrame(np.zeros(test_sample_num)), X1_data_user_test, pd.DataFrame(\n",
    "                         np.zeros(test_sample_num)),\n",
    "                     X1_data_item_test, pd.DataFrame(np.zeros(test_sample_num)), pd.DataFrame(Y0_data_test), pd.DataFrame(Y1_data_test)]\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    def train(self, data, labels, plot_list=[], verbose=0, epoches=20, batchsize=128):\n",
    "        \"\"\"\n",
    "        model train and save as tf serving model\n",
    "        :param cate_feature_dict: dict, categorical feature for data\n",
    "        :param user_cate_feature_dict: dict, user categorical feature\n",
    "        :param item_cate_feature_dict: dict, item categorical feature\n",
    "        :param train_data: DataFrame, training data\n",
    "        :param val_data: DataFrame, valdation data\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        cate_feature_dict = {}\n",
    "\n",
    "        train_data, val_data, test_data = self.preprocess_data(data, labels)\n",
    "\n",
    "#         ctcvr = CTCVRNet()\n",
    "        self.ctcvr_model = self.build()\n",
    "        opt = optimizers.Adam(learning_rate=0.003, decay=0.0001)\n",
    "        self.ctcvr_model.compile(optimizer=opt, loss=[\"binary_crossentropy\", \"binary_crossentropy\"], loss_weights=[1.0, 1.0],\n",
    "                                 metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "        # keras model save path\n",
    "        filepath = \"esmm_best.h5\"\n",
    "\n",
    "        # call back function\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.8, patience=2, min_lr=0.0001, verbose=0)\n",
    "        earlystopping = EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0.0001, patience=8, verbose=0, mode='auto')\n",
    "        callbacks = [checkpoint, reduce_lr, earlystopping]\n",
    "\n",
    "        # load data\n",
    "        ctr_user_numerical_feature_train, ctr_user_cate_feature_train, ctr_item_numerical_feature_train, \\\n",
    "            ctr_item_cate_feature_train, cvr_user_numerical_feature_train, cvr_user_cate_feature_train, \\\n",
    "            cvr_item_numerical_feature_train, cvr_item_cate_feature_train, ctr_target_train, cvr_target_train = train_data\n",
    "\n",
    "        ctr_user_numerical_feature_val, ctr_user_cate_feature_val, ctr_item_numerical_feature_val, \\\n",
    "            ctr_item_cate_feature_val, cvr_user_numerical_feature_val, cvr_user_cate_feature_val, \\\n",
    "            cvr_item_numerical_feature_val, cvr_item_cate_feature_val, ctr_target_val, cvr_target_val = val_data\n",
    "\n",
    "        ctr_user_numerical_feature_test, ctr_user_cate_feature_test, ctr_item_numerical_feature_test, \\\n",
    "            ctr_item_cate_feature_test, cvr_user_numerical_feature_test, cvr_user_cate_feature_test, \\\n",
    "            cvr_item_numerical_feature_test, cvr_item_cate_feature_test, ctr_target_test, cvr_target_test = test_data\n",
    "\n",
    "        # model train\n",
    "        history = self.ctcvr_model.fit([ctr_user_numerical_feature_train, ctr_user_cate_feature_train, ctr_item_numerical_feature_train,\n",
    "                                        ctr_item_cate_feature_train, cvr_user_numerical_feature_train, cvr_user_cate_feature_train,\n",
    "                                        cvr_item_numerical_feature_train,\n",
    "                                        cvr_item_cate_feature_train], [ctr_target_train, cvr_target_train], batch_size=batchsize, epochs=epoches,\n",
    "                                       validation_data=(\n",
    "            [ctr_user_numerical_feature_val, ctr_user_cate_feature_val, ctr_item_numerical_feature_val,\n",
    "             ctr_item_cate_feature_val, cvr_user_numerical_feature_val, cvr_user_cate_feature_val,\n",
    "             cvr_item_numerical_feature_val,\n",
    "             cvr_item_cate_feature_val], [ctr_target_val, cvr_target_val]),\n",
    "            #  callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            shuffle=True)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('Loss curve')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "        predictions = self.ctcvr_model.predict([ctr_user_numerical_feature_test, ctr_user_cate_feature_test, ctr_item_numerical_feature_test,\n",
    "                                                ctr_item_cate_feature_test, cvr_user_numerical_feature_test, cvr_user_cate_feature_test,\n",
    "                                                cvr_item_numerical_feature_test, cvr_item_cate_feature_test])\n",
    "\n",
    "        FPR, TPR, threshold = roc_curve(\n",
    "            ctr_target_test, predictions[0].reshape(-1))\n",
    "\n",
    "        AUC = auc(FPR, TPR)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Y1 ROC CURVE (AUC={:.2f})'.format(AUC))\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.plot(FPR, TPR, color='g')\n",
    "        plt.plot([0, 1], [0, 1], color='m', linestyle='--')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        precision, recall, thresholds = precision_recall_curve(\n",
    "            ctr_target_test, predictions[0].reshape(-1))\n",
    "        plt.title('Y1 PR CURVE')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.plot(recall, precision)\n",
    "        plt.show()\n",
    "\n",
    "        FPR, TPR, threshold = roc_curve(\n",
    "            cvr_target_test, predictions[1].reshape(-1))\n",
    "\n",
    "        AUC = auc(FPR, TPR)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Y2 ROC CURVE (AUC={:.2f})'.format(AUC))\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.plot(FPR, TPR, color='g')\n",
    "        plt.plot([0, 1], [0, 1], color='m', linestyle='--')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        precision, recall, thresholds = precision_recall_curve(\n",
    "            cvr_target_test, predictions[1].reshape(-1))\n",
    "        plt.title('Y2 PR CURVE')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.plot(recall, precision)\n",
    "        plt.show()\n",
    "        # load model and save as tf_serving model\n",
    "        # saved_model_path = './esmm/{}'.format(int(time.time()))\n",
    "        # ctcvr_model = tf.keras.models.load_model('esmm_best.h5')\n",
    "        # tf.saved_model.save(ctcvr_model, saved_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_label(df,labels, default_value=-1):\n",
    "    for label in labels:\n",
    "        if label not in df.columns:\n",
    "            df[label]=default_value\n",
    "    return df\n",
    "    \n",
    "def get_data(folderpath, labels):\n",
    "    # build synthetic training data\n",
    "    dataset_filenemes=os.listdir(folderpath)\n",
    "    dataset_filenemes=[f for f in dataset_filenemes if os.path.isfile(os.path.join(folderpath,f))]\n",
    "    print(f\"Datasets used : {list(dataset_filenemes)}\")\n",
    "    \n",
    "    data=pd.read_csv(os.path.join(folderpath,dataset_filenemes[0]))\n",
    "    data=filter_label(data, labels)\n",
    "    data=data.fillna(0)\n",
    "    all_features=list(set(data.columns)-set(labels))\n",
    "    print(f\"All features we used: {all_features if len(all_features)<=10 else all_features[:10]} (at most 10)\")\n",
    "    for i,file_name in enumerate(dataset_filenemes[1:]):\n",
    "        _data=pd.read_csv(os.path.join(folderpath,file_name))\n",
    "        _data=_data.fillna(0)\n",
    "        _data=filter_label(_data, all_features,default_value=0)\n",
    "        _data=filter_label(_data, labels)\n",
    "        _data=_data[all_features+labels]\n",
    "\n",
    "        data=data.append(_data)\n",
    "\n",
    "    data=data.sample(frac=1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qG-qgXBLE9A_"
   },
   "outputs": [],
   "source": [
    "data=get_data(\"/mnt/w/6998/Project/data/Generated\",labels=[\"label0\",\"label1\"])\n",
    "model=model=CTCVRNet()\n",
    "model.train(data,[\"label0\",\"label1\"], plot_list=[\"loss\",\"accuracy\",\"auc\",\"pr\"],epoches=5 ,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM5gutSGVJCxALxRtXdy6mT",
   "collapsed_sections": [],
   "name": "new 6998 project 3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
